{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv; load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* /Users/harukary/Documents/workspace/llm_samples/.venv/lib/python3.10/site-packages/langchain/chains/elasticsearch_database/base.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\"\"\"Chain for interacting with Elasticsearch Database.\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "from typing import TYPE_CHECKING, Any, Dict, List, Optional\n",
    "\n",
    "from langchain_core.language_models import BaseLanguageModel\n",
    "from langchain_core.output_parsers import BaseLLMOutputParser\n",
    "from langchain_core.prompts import BasePromptTemplate\n",
    "from langchain_core.pydantic_v1 import Extra, root_validator\n",
    "\n",
    "from langchain.callbacks.manager import CallbackManagerForChainRun\n",
    "from langchain.chains.base import Chain\n",
    "from langchain.chains.elasticsearch_database.prompts import ANSWER_PROMPT, DSL_PROMPT\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from elasticsearch import Elasticsearch\n",
    "from opensearchpy import OpenSearch\n",
    "\n",
    "INTERMEDIATE_STEPS_KEY = \"intermediate_steps\"\n",
    "\n",
    "\n",
    "class ElasticsearchDatabaseChain(Chain):\n",
    "    \"\"\"Chain for interacting with Elasticsearch Database.\n",
    "\n",
    "    Example:\n",
    "        .. code-block:: python\n",
    "\n",
    "            from langchain.chains import ElasticsearchDatabaseChain\n",
    "            from langchain_community.llms import OpenAI\n",
    "            from elasticsearch import Elasticsearch\n",
    "\n",
    "            database = Elasticsearch(\"http://localhost:9200\")\n",
    "            db_chain = ElasticsearchDatabaseChain.from_llm(OpenAI(), database)\n",
    "    \"\"\"\n",
    "\n",
    "    query_chain: LLMChain\n",
    "    \"\"\"Chain for creating the ES query.\"\"\"\n",
    "    answer_chain: LLMChain\n",
    "    \"\"\"Chain for answering the user question.\"\"\"\n",
    "    database: Any\n",
    "    \"\"\"Elasticsearch database to connect to of type elasticsearch.Elasticsearch.\"\"\"\n",
    "    top_k: int = 10\n",
    "    \"\"\"Number of results to return from the query\"\"\"\n",
    "    ignore_indices: Optional[List[str]] = None\n",
    "    include_indices: Optional[List[str]] = None\n",
    "    input_key: str = \"question\"  #: :meta private:\n",
    "    output_key: str = \"result\"  #: :meta private:\n",
    "    sample_documents_in_index_info: int = 3\n",
    "    return_intermediate_steps: bool = False\n",
    "    \"\"\"Whether or not to return the intermediate steps along with the final answer.\"\"\"\n",
    "\n",
    "    class Config:\n",
    "        \"\"\"Configuration for this pydantic object.\"\"\"\n",
    "\n",
    "        extra = Extra.forbid\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    @root_validator()\n",
    "    def validate_indices(cls, values: dict) -> dict:\n",
    "        if values[\"include_indices\"] and values[\"ignore_indices\"]:\n",
    "            raise ValueError(\n",
    "                \"Cannot specify both 'include_indices' and 'ignore_indices'.\"\n",
    "            )\n",
    "        return values\n",
    "\n",
    "    @property\n",
    "    def input_keys(self) -> List[str]:\n",
    "        \"\"\"Return the singular input key.\n",
    "\n",
    "        :meta private:\n",
    "        \"\"\"\n",
    "        return [self.input_key]\n",
    "\n",
    "    @property\n",
    "    def output_keys(self) -> List[str]:\n",
    "        \"\"\"Return the singular output key.\n",
    "\n",
    "        :meta private:\n",
    "        \"\"\"\n",
    "        if not self.return_intermediate_steps:\n",
    "            return [self.output_key]\n",
    "        else:\n",
    "            return [self.output_key, INTERMEDIATE_STEPS_KEY]\n",
    "\n",
    "    def _list_indices(self) -> List[str]:\n",
    "        all_indices = [\n",
    "            index[\"index\"] for index in self.database.cat.indices(format=\"json\")\n",
    "        ]\n",
    "\n",
    "        if self.include_indices:\n",
    "            all_indices = [i for i in all_indices if i in self.include_indices]\n",
    "        if self.ignore_indices:\n",
    "            all_indices = [i for i in all_indices if i not in self.ignore_indices]\n",
    "\n",
    "        return all_indices\n",
    "\n",
    "    def _get_indices_infos(self, indices: List[str]) -> str:\n",
    "        mappings = self.database.indices.get_mapping(index=\",\".join(indices))\n",
    "        if self.sample_documents_in_index_info > 0:\n",
    "            for k, v in mappings.items():\n",
    "                if isinstance(self.database, OpenSearch):\n",
    "                    hits = self.database.search(\n",
    "                        index=k,\n",
    "                        body={\"query\": {\"match_all\": {}},'_source':{'excludes':['vector_field']}},\n",
    "                        size=self.sample_documents_in_index_info,\n",
    "                    )[\"hits\"][\"hits\"]\n",
    "                else:\n",
    "                    hits = self.database.search(\n",
    "                        index=k,\n",
    "                        query={\"match_all\": {}},\n",
    "                        size=self.sample_documents_in_index_info,\n",
    "                    )[\"hits\"][\"hits\"]\n",
    "                hits = [str(hit[\"_source\"]) for hit in hits]\n",
    "                mappings[k][\"mappings\"] = str(v) + \"\\n\\n/*\\n\" + \"\\n\".join(hits) + \"\\n*/\"\n",
    "        return \"\\n\\n\".join(\n",
    "            [\n",
    "                \"Mapping for index {}:\\n{}\".format(index, mappings[index][\"mappings\"])\n",
    "                for index in mappings\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def _search(self, indices: List[str], query: str) -> str:\n",
    "        print(query)\n",
    "        result = self.database.search(index=\",\".join(indices), body=query)\n",
    "        return str(result)\n",
    "\n",
    "    def _call(\n",
    "        self,\n",
    "        inputs: Dict[str, Any],\n",
    "        run_manager: Optional[CallbackManagerForChainRun] = None,\n",
    "    ) -> Dict[str, Any]:\n",
    "        _run_manager = run_manager or CallbackManagerForChainRun.get_noop_manager()\n",
    "        input_text = f\"{inputs[self.input_key]}\\nESQuery:\"\n",
    "        _run_manager.on_text(input_text, verbose=self.verbose)\n",
    "        indices = self._list_indices()\n",
    "        indices_info = self._get_indices_infos(indices)\n",
    "        query_inputs: dict = {\n",
    "            \"input\": input_text,\n",
    "            \"top_k\": str(self.top_k),\n",
    "            \"indices_info\": indices_info,\n",
    "            \"stop\": [\"\\nESResult:\"],\n",
    "        }\n",
    "        intermediate_steps: List = []\n",
    "        try:\n",
    "            intermediate_steps.append(query_inputs)  # input: es generation\n",
    "            es_cmd = self.query_chain.run(\n",
    "                callbacks=_run_manager.get_child(),\n",
    "                **query_inputs,\n",
    "            )\n",
    "\n",
    "            _run_manager.on_text(es_cmd, color=\"green\", verbose=self.verbose)\n",
    "            intermediate_steps.append(\n",
    "                es_cmd\n",
    "            )  # output: elasticsearch dsl generation (no checker)\n",
    "            intermediate_steps.append({\"es_cmd\": es_cmd})  # input: ES search\n",
    "            result = self._search(indices=indices, query=es_cmd)\n",
    "            intermediate_steps.append(str(result))  # output: ES search\n",
    "\n",
    "            _run_manager.on_text(\"\\nESResult: \", verbose=self.verbose)\n",
    "            _run_manager.on_text(result, color=\"yellow\", verbose=self.verbose)\n",
    "\n",
    "            _run_manager.on_text(\"\\nAnswer:\", verbose=self.verbose)\n",
    "            answer_inputs: dict = {\"data\": result, \"input\": input_text}\n",
    "            intermediate_steps.append(answer_inputs)  # input: final answer\n",
    "            final_result = self.answer_chain.run(\n",
    "                callbacks=_run_manager.get_child(),\n",
    "                **answer_inputs,\n",
    "            )\n",
    "\n",
    "            intermediate_steps.append(final_result)  # output: final answer\n",
    "            _run_manager.on_text(final_result, color=\"green\", verbose=self.verbose)\n",
    "            chain_result: Dict[str, Any] = {self.output_key: final_result}\n",
    "            if self.return_intermediate_steps:\n",
    "                chain_result[INTERMEDIATE_STEPS_KEY] = intermediate_steps\n",
    "            return chain_result\n",
    "        except Exception as exc:\n",
    "            # Append intermediate steps to exception, to aid in logging and later\n",
    "            # improvement of few shot prompt seeds\n",
    "            exc.intermediate_steps = intermediate_steps  # type: ignore\n",
    "            raise exc\n",
    "\n",
    "    @property\n",
    "    def _chain_type(self) -> str:\n",
    "        return \"elasticsearch_database_chain\"\n",
    "\n",
    "    @classmethod\n",
    "    def from_llm(\n",
    "        cls,\n",
    "        llm: BaseLanguageModel,\n",
    "        database: Elasticsearch or OpenSearch,\n",
    "        *,\n",
    "        query_prompt: Optional[BasePromptTemplate] = None,\n",
    "        answer_prompt: Optional[BasePromptTemplate] = None,\n",
    "        query_output_parser: Optional[BaseLLMOutputParser] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> ElasticsearchDatabaseChain:\n",
    "        \"\"\"Convenience method to construct ElasticsearchDatabaseChain from an LLM.\n",
    "\n",
    "        Args:\n",
    "            llm: The language model to use.\n",
    "            database: The Elasticsearch db.\n",
    "            query_prompt: The prompt to use for query construction.\n",
    "            answer_prompt: The prompt to use for answering user question given data.\n",
    "            query_output_parser: The output parser to use for parsing model-generated\n",
    "                ES query. Defaults to SimpleJsonOutputParser.\n",
    "            **kwargs: Additional arguments to pass to the constructor.\n",
    "        \"\"\"\n",
    "        query_prompt = query_prompt or DSL_PROMPT\n",
    "        query_output_parser = query_output_parser or SimpleJsonOutputParser()\n",
    "        query_chain = LLMChain(\n",
    "            llm=llm, prompt=query_prompt, output_parser=query_output_parser\n",
    "        )\n",
    "        answer_prompt = answer_prompt or ANSWER_PROMPT\n",
    "        answer_chain = LLMChain(llm=llm, prompt=answer_prompt)\n",
    "        return cls(\n",
    "            query_chain=query_chain,\n",
    "            answer_chain=answer_chain,\n",
    "            database=database,\n",
    "            **kwargs,\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install opensearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.elasticsearch_database import ElasticsearchDatabaseChain\n",
    "# from langchain_community.llms import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from elasticsearch import Elasticsearch\n",
    "from opensearchpy import OpenSearch\n",
    "\n",
    "database = OpenSearch(\"http://localhost:9200\")\n",
    "db_chain = ElasticsearchDatabaseChain.from_llm(ChatOpenAI(model='gpt-3.5-turbo-16k'), database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harukary/Documents/workspace/llm_samples/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/Users/harukary/Documents/workspace/llm_samples/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': {'match': {'title': '清水寺'}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harukary/Documents/workspace/llm_samples/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/Users/harukary/Documents/workspace/llm_samples/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': '清水寺について教えて',\n",
       " 'result': \"Question: 清水寺について教えて\\nData: No relevant data found\\nAnswer: I'm sorry, but I couldn't find any information about 清水寺.\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_chain.invoke({\"question\":\"清水寺について教えて\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
