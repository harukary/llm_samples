{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,openai,json\n",
    "from dotenv import find_dotenv,load_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DSL_TEMPLATE = \"\"\"\\\n",
    "Given an input question, create a syntactically correct Elasticsearch query to run. \\\n",
    "Unless the user specifies in their question a specific number of examples they wish to obtain, \\\n",
    "always limit your query to at most {top_k} results. \\\n",
    "You can order the results by a relevant column to return the most interesting examples in the database.\n",
    "\n",
    "Unless told to do not query for all the columns from a specific index, \\\n",
    "only ask for a the few relevant columns given the question.\n",
    "\n",
    "Pay attention to use only the column names that you can see in the mapping description. \\\n",
    "Be careful to not query for columns that do not exist. Also, pay attention to which column is in which index. \\\n",
    "Return the query as valid json.\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: Question here\n",
    "ESQuery: Elasticsearch Query formatted as json\n",
    "\n",
    "Mapping: {mapping}\n",
    "\n",
    "Question: {input}\n",
    "ESQuery:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 3\n",
    "\n",
    "mapping = {\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "      \"name\":    { \"type\" : \"text\" },\n",
    "      \"age\":     { \"type\" : \"integer\" },\n",
    "      \"occupation\":{ \"type\" : \"text\" }\n",
    "    }\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '19歳以下の会社員を教えてください。'\n",
    "prompt = DSL_TEMPLATE.format(\n",
    "    top_k=top_k,\n",
    "    mapping=json.dumps(mapping,indent=2),\n",
    "    input=query\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_os_dsl(query):\n",
    "    prompt = DSL_TEMPLATE.format(\n",
    "        top_k=top_k,\n",
    "        mapping=json.dumps(mapping,indent=2),\n",
    "        input=query\n",
    "    )\n",
    "    chat = ChatOpenAI()\n",
    "    messages = [HumanMessage(content=prompt)]\n",
    "    response = chat(messages)\n",
    "    # print(response.content)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 19歳以下の会社員を教えてください。\n",
      "ESQuery: \n",
      "{\n",
      "  \"query\": {\n",
      "    \"bool\": {\n",
      "      \"must\": [\n",
      "        {\n",
      "          \"range\": {\n",
      "            \"age\": {\n",
      "              \"lte\": 19\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"match\": {\n",
      "            \"occupation\": \"会社員\"\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"size\": 3\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query = '19歳以下の会社員を教えてください。'\n",
    "response = get_os_dsl(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"query\": {\n",
      "    \"match\": {\n",
      "      \"name\": \"加藤さん\"\n",
      "    }\n",
      "  },\n",
      "  \"aggs\": {\n",
      "    \"average_age\": {\n",
      "      \"avg\": {\n",
      "        \"field\": \"age\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"size\": 3\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query = '加藤さんの年齢の平均を教えてください。'\n",
    "response = get_os_dsl(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "enc = tiktoken.encoding_for_model(model_name='gpt-3.5-turbo')\n",
    "print(len(enc.encode(prompt)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
